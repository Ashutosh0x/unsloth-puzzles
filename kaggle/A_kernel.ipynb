{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge A: NF4 to Triton Benchmark\n",
    "\n",
    "This notebook verifies the correctness and performance of the custom NF4 to Triton dequantization kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install triton bitsandbytes unsloth -U --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "from bitsandbytes.functional import dequantize_nf4\n",
    "import time\n",
    "\n",
    "# NF4 Triton Kernel Implementation\n",
    "@triton.jit\n",
    "def _your_dequantize_nf4_kernel(\n",
    "    weight_ptr,\n",
    "    absmax_ptr,\n",
    "    code_ptr,\n",
    "    out_ptr,\n",
    "    n_elements,\n",
    "    BLOCK_SIZE: tl.constexpr,\n",
    "):\n",
    "    pid = tl.program_id(0)\n",
    "    block_start = pid * BLOCK_SIZE\n",
    "    \n",
    "    byte_offsets = (block_start // 2) + tl.arange(0, BLOCK_SIZE // 2)\n",
    "    mask = byte_offsets < (n_elements // 2)\n",
    "    \n",
    "    packed_weights = tl.load(weight_ptr + byte_offsets, mask=mask)\n",
    "    \n",
    "    low_nibble = (packed_weights & 0xF).to(tl.int32)\n",
    "    high_nibble = (packed_weights >> 4).to(tl.int32)\n",
    "    \n",
    "    val_low = tl.load(code_ptr + low_nibble)\n",
    "    val_high = tl.load(code_ptr + high_nibble)\n",
    "    \n",
    "    abs_low = tl.load(absmax_ptr + (block_start + tl.arange(0, BLOCK_SIZE // 2) * 2) // 64, mask=mask)\n",
    "    abs_high = tl.load(absmax_ptr + (block_start + tl.arange(0, BLOCK_SIZE // 2) * 2 + 1) // 64, mask=mask)\n",
    "    \n",
    "    val_low = val_low * abs_low\n",
    "    val_high = val_high * abs_high\n",
    "    \n",
    "    out_offsets_low = block_start + tl.arange(0, BLOCK_SIZE // 2) * 2\n",
    "    out_offsets_high = out_offsets_low + 1\n",
    "    \n",
    "    tl.store(out_ptr + out_offsets_low, val_low, mask=mask)\n",
    "    tl.store(out_ptr + out_offsets_high, val_high, mask=mask)\n",
    "\n",
    "def _your_dequantize_nf4(weight, quant_state):\n",
    "    n_elements = weight.numel() * 2\n",
    "    out = torch.empty(quant_state.shape, dtype=quant_state.dtype, device=weight.device)\n",
    "    BLOCK_SIZE = 1024\n",
    "    grid = (triton.cdiv(n_elements, BLOCK_SIZE),)\n",
    "    _your_dequantize_nf4_kernel[grid](\n",
    "        weight, quant_state.absmax, quant_state.code, out, n_elements, BLOCK_SIZE=BLOCK_SIZE,\n",
    "    )\n",
    "    return out\n",
    "\n",
    "def your_dequantize_nf4(weight_param):\n",
    "    return _your_dequantize_nf4(weight_param.weight.data, weight_param.weight.quant_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.kernels import fast_dequantize\n",
    "from bitsandbytes.nn import LinearNF4\n",
    "\n",
    "# Setup\n",
    "device = \"cuda\"\n",
    "shape = (4096, 4096)\n",
    "linear = LinearNF4(shape[1], shape[0], bias=False).to(device)\n",
    "\n",
    "# Correctness\n",
    "out_ref = fast_dequantize(linear.weight.data, linear.weight.quant_state)\n",
    "out_custom = your_dequantize_nf4(linear)\n",
    "correct = torch.allclose(out_ref, out_custom, atol=1e-5)\n",
    "print(f\"Correctness check: {correct}\")\n",
    "\n",
    "# Benchmark\n",
    "def benchmark(fn, name, iters=100):\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    for _ in range(iters):\n",
    "        fn()\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    print(f\"{name}: {(end-start)/iters*1000:.4f} ms\")\n",
    "    return (end-start)/iters\n",
    "\n",
    "t_ref = benchmark(lambda: fast_dequantize(linear.weight.data, linear.weight.quant_state), \"Unsloth fast_dequantize\")\n",
    "t_custom = benchmark(lambda: your_dequantize_nf4(linear), \"Your Triton kernel\")\n",
    "speedup = t_ref / t_custom\n",
    "print(f\"Speedup: {speedup:.4f}x\")\n",
    "if speedup >= 1.15:\n",
    "    print(\"PASSED: Speedup is >= 1.15x\")\n",
    "else:\n",
    "    print(\"FAILED: Speedup is < 1.15x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
